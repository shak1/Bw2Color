{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bw2Color_ResNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHfw3_60sbnO"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw45vVGFdFdp"
      },
      "source": [
        "!pip install -q -U progressbar2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceXOdXEIcqrt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import  Model\n",
        "import os\n",
        "from math import log2\n",
        "import time\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "from keras.callbacks import *\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "import shutil\n",
        "import progressbar\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.image import ResizeMethod\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "plt.ioff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "512oCoGLdQg-"
      },
      "source": [
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE= 16\n",
        "EPOCHS = 30\n",
        "PRETRAIN_EPOCHS = 50\n",
        "IMG_SIZE = 128\n",
        "OUTPUT_CHANNELS = 2\n",
        "LAMBDA = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47MZB9LMvgLQ",
        "outputId": "550023d1-65d8-431b-de9e-0dfe5ccfc5c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjIXznY5eIHy"
      },
      "source": [
        "shutil.copy(\"/content/drive/My Drive/VCS Project/Train.zip\", \".\")\n",
        "!unzip -q Train.zip\n",
        "!rm Train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i5rEK-grh7U"
      },
      "source": [
        "shutil.copy(\"/content/drive/My Drive/VCS Project/Val.zip\", \".\")\n",
        "!unzip -q Val.zip\n",
        "!rm Val.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6MT9V9mAD5l"
      },
      "source": [
        "def convert2lab(img):\n",
        "  srgb_pixels = tf.reshape(img, [-1, 3])\n",
        "  \n",
        "  linear_mask = tf.cast(srgb_pixels <= 0.04045, dtype=tf.float32)\n",
        "  exponential_mask = tf.cast(srgb_pixels > 0.04045, dtype=tf.float32)\n",
        "  rgb_pixels = (srgb_pixels / 12.92 * linear_mask) + (((srgb_pixels + 0.055) / 1.055) ** 2.4) * exponential_mask\n",
        "  rgb_to_xyz = tf.constant([\n",
        "      #    X        Y          Z\n",
        "      [0.412453, 0.212671, 0.019334], # R\n",
        "      [0.357580, 0.715160, 0.119193], # G\n",
        "      [0.180423, 0.072169, 0.950227], # B\n",
        "  ])\n",
        "  xyz_pixels = tf.matmul(rgb_pixels, rgb_to_xyz)\n",
        " \n",
        "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "  xyz_normalized_pixels = tf.multiply(xyz_pixels, [1/0.950456, 1.0, 1/1.088754])\n",
        " \n",
        "  epsilon = 6/29\n",
        "  linear_mask = tf.cast(xyz_normalized_pixels <= (epsilon**3), dtype=tf.float32)\n",
        "  exponential_mask = tf.cast(xyz_normalized_pixels > (epsilon**3), dtype=tf.float32)\n",
        "  fxfyfz_pixels = (xyz_normalized_pixels / (3 * epsilon**2) + 4/29) * linear_mask + (xyz_normalized_pixels ** (1/3)) * exponential_mask\n",
        " \n",
        "  # convert to lab\n",
        "  fxfyfz_to_lab = tf.constant([\n",
        "      #  l       a       b\n",
        "      [  0.0,  500.0,    0.0], # fx\n",
        "      [116.0, -500.0,  200.0], # fy\n",
        "      [  0.0,    0.0, -200.0], # fz\n",
        "  ])\n",
        "  lab_pixels = tf.matmul(fxfyfz_pixels, fxfyfz_to_lab) + tf.constant([-16.0, 0.0, 0.0])\n",
        " \n",
        "  return tf.reshape(lab_pixels, tf.shape(img))\n",
        "\n",
        "def convert2rgb(lab):\n",
        "  lab_pixels = tf.reshape(lab, [-1, 3])\n",
        "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "  # convert to fxfyfz\n",
        "  lab_to_fxfyfz = tf.constant([\n",
        "      #   fx      fy        fz\n",
        "      [1/116.0, 1/116.0,  1/116.0], # l\n",
        "      [1/500.0,     0.0,      0.0], # a\n",
        "      [    0.0,     0.0, -1/200.0], # b\n",
        "  ])\n",
        "  fxfyfz_pixels = tf.matmul(lab_pixels + tf.constant([16.0, 0.0, 0.0]), lab_to_fxfyfz)\n",
        "\n",
        "  # convert to xyz\n",
        "  epsilon = 6/29\n",
        "  linear_mask = tf.cast(fxfyfz_pixels <= epsilon, dtype=tf.float32)\n",
        "  exponential_mask = tf.cast(fxfyfz_pixels > epsilon, dtype=tf.float32)\n",
        "  xyz_pixels = (3 * epsilon**2 * (fxfyfz_pixels - 4/29)) * linear_mask + (fxfyfz_pixels ** 3) * exponential_mask\n",
        "\n",
        "    # denormalize for D65 white point\n",
        "  xyz_pixels = tf.multiply(xyz_pixels, [0.950456, 1.0, 1.088754])\n",
        "\n",
        "      \n",
        "  xyz_to_rgb = tf.constant([\n",
        "      #     r           g          b\n",
        "      [ 3.2404542, -0.9692660,  0.0556434], # x\n",
        "      [-1.5371385,  1.8760108, -0.2040259], # y\n",
        "      [-0.4985314,  0.0415560,  1.0572252], # z\n",
        "  ])\n",
        "  rgb_pixels = tf.matmul(xyz_pixels, xyz_to_rgb)\n",
        "  # avoid a slightly negative number messing up the conversion\n",
        "  rgb_pixels = tf.clip_by_value(rgb_pixels, 0.0, 1.0)\n",
        "  linear_mask = tf.cast(rgb_pixels <= 0.0031308, dtype=tf.float32)\n",
        "  exponential_mask = tf.cast(rgb_pixels > 0.0031308, dtype=tf.float32)\n",
        "  srgb_pixels = (rgb_pixels * 12.92 * linear_mask) + ((rgb_pixels ** (1/2.4) * 1.055) - 0.055) * exponential_mask\n",
        "\n",
        "  return tf.reshape(srgb_pixels, tf.shape(lab))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Iy5SyOdXTx"
      },
      "source": [
        "def resize_with_ratio(img, size):\n",
        "  w, h = tf.shape(img)[0], tf.shape(img)[1]\n",
        " \n",
        "  new_height = h * size // tf.minimum(w, h)\n",
        "  new_width = w * size // tf.minimum(w, h)\n",
        "  \n",
        "  img = tf.image.resize(img, [new_width, new_height], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return img\n",
        " \n",
        "def center_crop(img, size):\n",
        "  w, h = tf.shape(img)[0], tf.shape(img)[1]\n",
        "  x = (w - IMG_SIZE)//2\n",
        "  y = (h - IMG_SIZE)//2\n",
        "  img = tf.image.crop_to_bounding_box(img, x, y, IMG_SIZE, IMG_SIZE)\n",
        "  return img\n",
        " \n",
        "def normalise(lab_imgs):\n",
        "  imgs = tf.reshape(lab_imgs, [-1, 3])\n",
        "  normalised = imgs / [100.0, 110.0, 110.0]\n",
        "  return tf.reshape(normalised, tf.shape(lab_imgs))\n",
        "\n",
        "def denormalise(lab_imgs):\n",
        "  imgs = tf.reshape(lab_imgs, [-1, 3])\n",
        "  unormalised = imgs * [100.0, 110.0, 110.0]\n",
        "  return tf.reshape(unormalised, tf.shape(lab_imgs))\n",
        "\n",
        " \n",
        "def data_augmentation(img):\n",
        "  img = tf.image.random_flip_left_right(img)\n",
        "  return img\n",
        "\n",
        "\n",
        "def post_process(L, AB, rescale=False):\n",
        "  image_lab = tf.concat([L, AB], axis=-1)\n",
        "  image_lab = denormalise(image_lab)\n",
        "  img_rgb = convert2rgb(image_lab)\n",
        "  if rescale:\n",
        "    img_rgb = img_rgb*255.0\n",
        "\n",
        "  return img_rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqKJzF-5dp_S"
      },
      "source": [
        "def load(image_path):\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.cast(img, dtype=tf.float32)/255.0\n",
        "  return img\n",
        " \n",
        "def load_image_train(file_path):\n",
        "  img = load(file_path)\n",
        "  img = tf.image.random_flip_left_right(img)\n",
        "  lab_img = convert2lab(img)\n",
        "  lab_img = normalise(lab_img)\n",
        "  L = lab_img[:,:,0][..., tf.newaxis]\n",
        "  AB = tf.stack([lab_img[:,:,1], lab_img[:,:,2]], axis=-1)\n",
        "  return L, AB, file_path\n",
        " \n",
        "#load an image and cretes the couple (L, RGB)\n",
        "def load_image_test(file_path):\n",
        "  #load image as RGB\n",
        "  img = load(file_path)\n",
        "  #Convert the image to LAB Space\n",
        "  lab_img = convert2lab(img)\n",
        "  #Nomalise the values so that they are in the range [-1, -1]\n",
        "  lab_img = normalise(lab_img)\n",
        "  #Extract the L channel\n",
        "  L = lab_img[:,:,0][..., tf.newaxis]\n",
        "  return L, img, file_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XZOHuRJoThV"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        " \r\n",
        "train_dataset = tf.data.Dataset.list_files('/content/Train/*.jpg')\r\n",
        "                                              \r\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\\\r\n",
        "                            .map(load_image_train, num_parallel_calls=AUTOTUNE)\\\r\n",
        "                            .batch(BATCH_SIZE)\\\r\n",
        "                            .prefetch(AUTOTUNE)\r\n",
        "\r\n",
        "val_dataset = tf.data.Dataset.list_files('/content/Val/*.jpg', shuffle=False)\r\n",
        "                                              \r\n",
        "val_dataset = val_dataset.map(load_image_test)\\\r\n",
        "                          .batch(BATCH_SIZE)\\\r\n",
        "                          .prefetch(AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ZznMUV-5lP"
      },
      "source": [
        "# ResNet Backbone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSWx0icvTENL"
      },
      "source": [
        "class Resize_Conv2D(Layer):\n",
        "  def __init__(self, filters, kernel, stride, use_bias=False, upsampling_factor=2):\n",
        "        self.filters = filters\n",
        "        self.kernel = kernel\n",
        "        self.stride = stride\n",
        "        self.use_bias = use_bias\n",
        "        self.upsampling_factor = upsampling_factor\n",
        "        \n",
        "        super(Resize_Conv2D, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    pad = self.kernel // 2\n",
        "\n",
        "    self.paddings = tf.constant([[0, 0], [pad, pad],[pad, pad], [0, 0]])\n",
        "    self.conv2d = Conv2D(self.filters, self.kernel, self.stride, use_bias=self.use_bias,\n",
        "                         padding='valid', kernel_initializer=initializer)\n",
        "  def call(self, inputs):\n",
        "      new_h = inputs.shape[1] * self.upsampling_factor\n",
        "      new_w = inputs.shape[2] * self.upsampling_factor\n",
        "\n",
        "      x = tf.image.resize(inputs, [new_h, new_w], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "      x = tf.pad(x, self.paddings, mode='REFLECT')\n",
        "      x = self.conv2d(x)\n",
        "      return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3E9u9TETNmE"
      },
      "source": [
        "class ICNR(tf.keras.initializers.Initializer):\n",
        "  \n",
        "    def __init__(self, initializer, scale=1):\n",
        "      self.scale = scale\n",
        "      self.initializer = initializer\n",
        "\n",
        "    def __call__(self, shape, dtype):\n",
        "      shape = list(shape)\n",
        "      if self.scale == 1:\n",
        "          return self.initializer(shape)\n",
        "\n",
        "      new_shape = shape[:3] + [shape[3] // (self.scale ** 2)]\n",
        "      x = self.initializer(new_shape, dtype)\n",
        "      x = tf.transpose(x, perm=[2, 0, 1, 3])\n",
        "      x = tf.image.resize(x, size=(shape[0] * self.scale, shape[1] * self.scale),\n",
        "                          method=ResizeMethod.NEAREST_NEIGHBOR)\n",
        "      x = tf.nn.space_to_depth(x, block_size=self.scale)\n",
        "      x = tf.transpose(x, perm=[1, 2, 0, 3])\n",
        "\n",
        "      return x\n",
        "    def get_config(self):\n",
        "      return {\"scale\": self.scale, \"initilizer\": self.initializer}\n",
        "\n",
        "class PixelShuffle_ICNR(Layer):\n",
        "  def __init__(self, upsampling_factor=2, **kwargs):\n",
        "    self.upsampling_factor = upsampling_factor\n",
        "    super(PixelShuffle_ICNR, self).__init__(**kwargs)\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    filters = input_shape[-1]*(self.upsampling_factor**2)/2\n",
        "    self.conv = Conv2D(filters, kernel_size=(1, 1),\n",
        "                       kernel_initializer=ICNR(tf.keras.initializers.GlorotUniform(),\n",
        "                                               scale=self.upsampling_factor))\n",
        "    self.pixel_shuffle = Lambda(lambda x: self._pixel_shuffle(x))\n",
        "    self.replicate_pad = Lambda(lambda x: self._replicate_pad(x, padding=(1, 0, 1, 0)))\n",
        "    self.avg_polling =  AveragePooling2D(pool_size=(2,2), strides=(1, 1))\n",
        "  \n",
        "  def call(self, input):\n",
        "    x = self.conv(input)\n",
        "    x = self.pixel_shuffle(x)\n",
        "    x = self.replicate_pad(x)\n",
        "    x = self.avg_polling(x)\n",
        "\n",
        "    return tf.keras.activations.relu(x)\n",
        "\n",
        "  def get_config(self):\n",
        "\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'upsampling_factor': self.upsampling_factor\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def _pixel_shuffle(self, inputs):\n",
        "    return tf.nn.depth_to_space(inputs, self.upsampling_factor)\n",
        "\n",
        "  def _replicate_pad(self, input, padding=(1, 1, 1, 1)):\n",
        "    padding_left, padding_right = padding[0], padding[1]\n",
        "    padding_top, padding_bottom = padding[2], padding[3]\n",
        "    return tf.pad(input, [[0,0], [padding_top, padding_bottom],\n",
        "                          [padding_left, padding_right], [0,0] ], 'SYMMETRIC')\n",
        "\n",
        "get_custom_objects().update({'PixelShuffle_ICNR': PixelShuffle_ICNR})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bowGh9Q_2VS8"
      },
      "source": [
        "def build_resnet_model(input, network_config, include_top=True, with_skips=False):\n",
        "\n",
        "  def conv_norm_relu(input, filters, kernel_size, name, increase_dim=False):\n",
        "    x = input\n",
        "    if increase_dim:\n",
        "        x = ZeroPadding2D(padding=(1,1), name=name+'.pad')(x)\n",
        "        x = Conv2D(filters, kernel_size, strides=2, padding='valid',\n",
        "                          activation='linear', use_bias=False, name=name+'.conv1')(x)\n",
        "    else:\n",
        "        x = Conv2D(filters, kernel_size, strides=1, padding='same',\n",
        "                            activation='linear', use_bias=False, name=name+'.conv1')(x)      \n",
        "    \n",
        "    x = BatchNormalization(momentum=0.1, epsilon=1e-5, name=name+'.bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=1, padding='same',\n",
        "                              activation='linear', use_bias=False, name=name+'.conv2')(x)\n",
        "    x = BatchNormalization(momentum=0.1, epsilon=1e-5, name=name+'.bn2')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def res_block(input, filters, kernel_size, name, increase_dim=False):\n",
        "    x = input\n",
        "    F = conv_norm_relu(x, filters, kernel_size, name, increase_dim)\n",
        "    if increase_dim:\n",
        "      x = Conv2D(filters, kernel_size=1, strides=2, padding='same',\n",
        "                        activation='linear', use_bias=False, name=name+'.downsample.0')(x)\n",
        "      x = BatchNormalization(momentum=0.1, epsilon=1e-5, name=name+'.downsample.1')(x)\n",
        "      \n",
        "    x = Add()([F, x])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  x = input\n",
        "  \n",
        "  x = ZeroPadding2D(padding=(3,3), name='pad')(input)\n",
        "  x = Conv2D(filters=64, kernel_size=7, strides=2, padding='valid',\n",
        "             activation='linear', use_bias=False, name='conv1')(x)\n",
        "  x = BatchNormalization(momentum=0.1, epsilon=1e-5, name='bn1')(x)\n",
        "  x = Activation('relu', name='relu')(x)\n",
        "  \n",
        "  skips = [x]\n",
        "\n",
        "  x = ZeroPadding2D(padding=(1,1), name='pad1')(x)\n",
        "  x = MaxPool2D(pool_size=3, strides=2, padding='valid', name='maxpool')(x)\n",
        "  \n",
        "  increase_dim = False\n",
        "  for layer in network_config.keys():\n",
        "    filters = network_config[layer]['filters']\n",
        "    blocks = network_config[layer]['blocks']\n",
        "    kernel_size = network_config[layer]['kernel_size']\n",
        "    \n",
        "    for j in range(blocks):\n",
        "      x = res_block(x, filters, kernel_size, name=f'{layer}.{j}', increase_dim=increase_dim)\n",
        "      increase_dim = False\n",
        "    \n",
        "    increase_dim = True\n",
        "\n",
        "    skips.append(x)\n",
        "\n",
        "  if include_top:\n",
        "    x = GlobalAveragePooling2D(name='avgpool')(x)\n",
        "    x = Dense(units=1000, use_bias=True, activation='linear', name='fc')(x)\n",
        "\n",
        "  model = tf.keras.Model(input, x)\n",
        "\n",
        "  if  with_skips:\n",
        "    return model, list(reversed(skips))[1:]\n",
        "  else:\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIU2Hlha47kY"
      },
      "source": [
        "def build_unet_model(model, skips, output_channel):\n",
        "\n",
        "  def up_sample_block(x, filters, name, kernel_size=3, bn=True, skip=None):\n",
        "    x = PixelShuffle_ICNR()(x)\n",
        "    if bn:\n",
        "      x = BatchNormalization(name=name+'.bn0')(x)\n",
        "    if skip is not None:\n",
        "      x = Concatenate(name=name+'.concatenate')([x, skip])\n",
        "    \n",
        "    x = Conv2D(filters, kernel_size, strides=1, padding='same', name=name+'.conv1')(x)\n",
        "    if bn:\n",
        "      x = BatchNormalization(name=name+'.bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=1, padding='same', name=name+'.conv2')(x)\n",
        "    if bn:\n",
        "      x = BatchNormalization(name=name+'.bn2')(x)\n",
        "    x = Activation('relu')(x)\n",
        "  \n",
        "    return x\n",
        "\n",
        "\n",
        "  x = model.output\n",
        "  filters = skips[0].shape[-1]\n",
        "  for i, skip in enumerate(skips):\n",
        "    x = up_sample_block(x, filters, name=f'decoder_layer.{i}', skip=skip)\n",
        "    filters = filters//2\n",
        "  \n",
        "  x = up_sample_block(x, filters, name=f'decoder_layer.{i+1}')\n",
        "\n",
        "  output = Conv2D(filters=output_channel, kernel_size=3, padding='same', name='final_conv')(x)\n",
        "\n",
        "  return tf.keras.Model(model.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9EGfrPFng_8"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjLXtuSafGPt"
      },
      "source": [
        "def define_generator(input_shape, output_channel):\n",
        "  input = Input(shape=input_shape)\n",
        "\n",
        "  network_config = {\n",
        "    'layer1': {'blocks':2, 'filters': 64, 'kernel_size':3},\n",
        "    'layer2': {'blocks':2, 'filters': 128, 'kernel_size':3},\n",
        "    'layer3': {'blocks':2, 'filters': 256, 'kernel_size':3},\n",
        "    'layer4': {'blocks':2, 'filters': 512, 'kernel_size':3}\n",
        "  }\n",
        "  backbone_resnet, skips = build_resnet_model(input, network_config, include_top=False, with_skips=True)\n",
        "\n",
        "  resnet_generator = build_unet_model(backbone_resnet, skips, output_channel)\n",
        "  \n",
        "  return resnet_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut1O40j3n5xn"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqjWABii_OSl"
      },
      "source": [
        "def down_sample(input, filters, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  x = Conv2D(filters, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(input)\n",
        "  if apply_batchnorm:\n",
        "    x = BatchNormalization()(x,training=True)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwOKFUeRfWM5"
      },
      "source": [
        "def define_discriminator(input_shape, target_shape):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  inp = Input(shape=input_shape, name='input_image')\n",
        "  tar = Input(shape=target_shape, name='target_image')\n",
        "\n",
        "  x = Concatenate()([inp, tar])\n",
        "\n",
        "  x = down_sample(x, 64, apply_batchnorm=False)\n",
        "  x = down_sample(x, 128)\n",
        "  x = down_sample(x, 256)\n",
        "\n",
        "  x = ZeroPadding2D()(x)\n",
        "  x = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(x)\n",
        "\n",
        "  x = BatchNormalization()(x, training=True)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = ZeroPadding2D()(x)\n",
        "\n",
        "  last = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)\n",
        "\n",
        "  return Model(inputs=[inp, tar], outputs=last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZFc4EQcn_rw"
      },
      "source": [
        "# Losses\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtcgyrZ_V0h"
      },
      "source": [
        "def feature_extractor_model(input_shape):\n",
        "  feature_layers = ['block1_conv1',\n",
        "                    'block1_conv2',\n",
        "                    'block3_conv1',\n",
        "                    'block4_conv1',\n",
        "                    'block5_conv1',\n",
        "                    'block5_conv2',\n",
        "                    'block5_conv3',\n",
        "                    'block5_conv4']\n",
        "\n",
        "\n",
        "  vgg_model = tf.keras.applications.VGG19(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n",
        "  vgg_model.trainable = False\n",
        "\n",
        "  outputs = [vgg_model.get_layer(layer).output for layer in feature_layers]\n",
        "  \n",
        "  extractor = tf.keras.Model(vgg_model.input, outputs)\n",
        "  return extractor\n",
        "\n",
        "@tf.function\n",
        "def feature_loss(feature_extractor, input_l, fake_ab, real_ab):\n",
        "  feature_weights = [10, 10, 7, 7, 10, 10, 10, 10]\n",
        "\n",
        "  fake_img = post_process(input_l, fake_ab, rescale=True)\n",
        "  real_img = post_process(input_l, real_ab, rescale=True)\n",
        "\n",
        "  fake_preprocessed = tf.keras.applications.vgg19.preprocess_input(fake_img)\n",
        "  real_preprocessed = tf.keras.applications.vgg19.preprocess_input(real_img)\n",
        "\n",
        "  fake_features = feature_extractor(fake_preprocessed)\n",
        "  real_features = feature_extractor(real_preprocessed)\n",
        "\n",
        "  loss = tf.add_n([tf.reduce_mean(tf.abs(real-fake))*w\n",
        "                        for real, fake, w in zip(real_features, fake_features, feature_weights)])\n",
        "  return loss\n",
        "\n",
        "loss_object = tf.keras.losses.MeanSquaredError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV0xzbhooMgg"
      },
      "source": [
        "# Generate images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tXgNh9RP7md"
      },
      "source": [
        "def generate_images(dataset, generator, save_path):\n",
        "  \n",
        "  def generate(dataset, generator):\n",
        "    batch_shape = tf.data.experimental.get_structure(dataset)[1].shape\n",
        "    fake_images = np.empty(shape=(0, IMG_SIZE, IMG_SIZE, 3))\n",
        "    inputs = np.empty(shape=(0, IMG_SIZE, IMG_SIZE, 1))\n",
        "    real_images = np.empty_like(fake_images)\n",
        "\n",
        "    for Ls, real in dataset:\n",
        "      fake_ABs = generator.predict(Ls)\n",
        "\n",
        "      fake_RGBs = post_process(Ls, fake_ABs)\n",
        "\n",
        "      fake_images = np.append(fake_images, fake_RGBs, axis=0)\n",
        "      inputs = np.append(inputs, Ls, axis=0)\n",
        "      real_images = np.append(real_images, real, axis=0)\n",
        "\n",
        "    return inputs, real_images, fake_images \n",
        "\n",
        "  fig =  plt.figure(dpi=300, figsize=(30,30), constrained_layout=False)\n",
        "\n",
        "  inputs, real_images, fake_images = generate(dataset, generator)\n",
        "  num_images = fake_images.shape[0]\n",
        "\n",
        "  grid = ImageGrid(fig, 141,  #\n",
        "                     nrows_ncols=(num_images, 3),\n",
        "                     axes_pad=0.01,\n",
        "                     label_mode=\"1\",\n",
        "                     )\n",
        "\n",
        "  title = ['Input','Real', 'Fake']\n",
        "\n",
        "  for n, (L, real, fake) in enumerate(zip(inputs, real_images, fake_images)):\n",
        "    input = (L[..., 0] + 1.0)/2.0\n",
        "    display_list = [input , real, fake]\n",
        "\n",
        "    for i in range(3):\n",
        "      ax = grid[n*3 + i]\n",
        "      ax.axis('off')\n",
        "      if n == 0:\n",
        "        ax.set_title(title[i])\n",
        "      if i == 0:\n",
        "        ax.imshow(display_list[i], cmap='gray', aspect='auto')\n",
        "      else:\n",
        "        ax.imshow(display_list[i], aspect='auto')\n",
        "      \n",
        "  fig.savefig(save_path, bbox_inches='tight', aspect='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hN-iJCuKFJy"
      },
      "source": [
        "# Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ8yCAZAfYQ-"
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/\"\n",
        " \n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0d2HnnsmGi"
      },
      "source": [
        "generator = define_generator([IMG_SIZE, IMG_SIZE, 1], OUTPUT_CHANNELS)\n",
        "optimizer = tf.keras.optimizers.Adam(0.0004, beta_1=0.5)\n",
        "feature_extractor = feature_extractor_model((IMG_SIZE, IMG_SIZE, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0pbwf-wsGoX"
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/VCS Project/pretrained'\n",
        "pretrianed_checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 generator=generator,\n",
        "                                 step=tf.Variable(0))\n",
        "pretrianed_manager = tf.train.CheckpointManager(pretrianed_checkpoint, checkpoint_dir, max_to_keep=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "week-Fu6CSr_"
      },
      "source": [
        "def pretrain_generator(train_ds, epochs):\n",
        "\n",
        "  widgets=[\n",
        "      progressbar.Bar(marker='=', left='[', right=']'),\n",
        "      progressbar.widgets.SimpleProgress(),\n",
        "      ' - ', progressbar.Timer(),'',\n",
        "      '-', progressbar.AdaptiveETA(), ''\n",
        "  ]\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(input, target, epoch):\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      gen_output = generator(input, training=True)\n",
        "      loss = feature_loss(feature_extractor, input, gen_output, target)\n",
        "\n",
        "    generator_gradients = gen_tape.gradient(loss, generator.trainable_variables)\n",
        "  \n",
        "    optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "\n",
        "    with summary_writer.as_default():\n",
        "      tf.summary.scalar('loss', loss, step=epoch)\n",
        "  \n",
        "  print('Starting pretraining generator...')\n",
        "  \n",
        "  pretrianed_checkpoint.restore(pretrianed_manager.latest_checkpoint)\n",
        "  if pretrianed_manager.latest_checkpoint:\n",
        "    print(\"Restored from {}\".format(pretrianed_manager.latest_checkpoint))\n",
        "  else:\n",
        "    print(\"Initializing from scratch.\")\n",
        "\n",
        "  step = int(pretrianed_checkpoint.step)\n",
        "  iters = train_ds.cardinality().numpy()\n",
        "  for epoch in range(step, epochs):\n",
        "\n",
        "    print(f'Epoch: {epoch}')\n",
        "    # Train\n",
        "    with progressbar.ProgressBar(max_value=iters, widgets=widgets) as pbar:\n",
        "      for n, (input_image, target, _) in train_ds.enumerate():\n",
        "    \n",
        "        train_step(input_image, target, epoch)\n",
        "        pbar.update(n.numpy())\n",
        "    print('')\n",
        "    \n",
        "    path = f'/content/drive/My Drive/VCS Project/pretrained/samples/sample_{epoch + 1}.jpg'\n",
        "    generate_images(val_dataset, generator, path);\n",
        "\n",
        "    pretrianed_checkpoint.step.assign_add(1)\n",
        "    if epoch >= 10:\n",
        "      pretrianed_manager.save()\n",
        "    \n",
        "\n",
        "    clear_output()             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n252WlTVgND5"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU-kJ7ieK__s"
      },
      "source": [
        "pretrain_generator(train_dataset, PRETRAIN_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRSgJwYWwg6b",
        "outputId": "ccb60810-49d2-4412-9e45-40a6877a44f7"
      },
      "source": [
        "pretrianed_checkpoint.restore(pretrianed_manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa0f076a358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOMpXe0KiPJL"
      },
      "source": [
        "generator.save_weights('/content/drive/My Drive/VCS Project/pretrained/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hec7-x6QKyMB"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AICkxOnfmxo",
        "outputId": "e9b44582-2b25-4d14-ee57-f2c23247910b"
      },
      "source": [
        "feature_extractor = feature_extractor_model((IMG_SIZE, IMG_SIZE, 3))\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jrXLaeLj0d_"
      },
      "source": [
        "generator = define_generator([IMG_SIZE, IMG_SIZE, 1], OUTPUT_CHANNELS)\n",
        "discriminator = define_discriminator([IMG_SIZE, IMG_SIZE, 1], [IMG_SIZE, IMG_SIZE, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFLei0brw4es",
        "outputId": "789dd3d6-0784-4d82-9258-7a023f6b75e4"
      },
      "source": [
        "generator.load_weights('/content/drive/My Drive/VCS Project/pretrained/').assert_consumed()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f16721c5a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ1TJGZKfMpg"
      },
      "source": [
        "def generator_loss(disc_generated_output, input, gen_output, target):\n",
        "  gan_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        " \n",
        "  f_loss = feature_loss(feature_extractor, input, gen_output, target)\n",
        "  \n",
        "  total_gen_loss = gan_loss + LAMBDA*f_loss\n",
        "\n",
        "  return total_gen_loss, gan_loss, f_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvqEEmXf1tv"
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        " \n",
        "  generated_loss = loss_object(tf.ones_like(disc_generated_output)*-1.0, disc_generated_output)\n",
        " \n",
        "  total_disc_loss = real_loss + generated_loss\n",
        " \n",
        "  return total_disc_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0eMDXlWf2OL"
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/\"\n",
        " \n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo5mQ3W8jtId"
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image)\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target])\n",
        "    disc_generated_output = discriminator([input_image, gen_output])\n",
        " \n",
        "    gen_total_loss, gen_gan_loss, f_loss = generator_loss(disc_generated_output, input_image, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        " \n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        " \n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        " \n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_f_loss', f_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3FdfZTk7J6"
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/VCS Project/checkpoints'\n",
        "checkpoints = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator,\n",
        "                                 step=tf.Variable(0))\n",
        "manager = tf.train.CheckpointManager(checkpoints, checkpoint_dir, max_to_keep=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FbjAJoj-99"
      },
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "import progressbar\n",
        "\n",
        "widgets=[\n",
        "    progressbar.Bar(marker='=', left='[', right=']'),\n",
        "    progressbar.widgets.SimpleProgress(),\n",
        "    ' - ', progressbar.Timer(), '',\n",
        "    '-', progressbar.AdaptiveETA(), ''\n",
        "]\n",
        "def fit(train_ds, epochs):\n",
        "  checkpoints.restore(manager.latest_checkpoint)\n",
        "\n",
        "  if manager.latest_checkpoint:\n",
        "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "  else:\n",
        "    print(\"Initializing from scratch.\")\n",
        "\n",
        "  step = int(checkpoints.step)\n",
        "  \n",
        "  for epoch in range(step, epochs):\n",
        "    start = time.time()\n",
        "    iters = train_ds.cardinality().numpy()\n",
        " \n",
        "    print(f'Epoch: {epoch + 1}')\n",
        "    # Train\n",
        "    with progressbar.ProgressBar(max_value=iters, widgets=widgets) as pbar:\n",
        "      for n, (input_image, target, _) in train_ds.enumerate():\n",
        "    \n",
        "        train_step(input_image, target, epoch)\n",
        "        pbar.update(n.numpy())\n",
        "        if (n+1) % 1000 == 0:\n",
        "          path = f'/content/drive/My Drive/VCS Project/samples/sample_{epoch+1}_{n+1}.jpg'\n",
        "          generate_images(val_dataset, generator , path)\n",
        "          manager.save()\n",
        "\n",
        "    path = f'/content/drive/My Drive/VCS Project/samples/sample_{epoch + 1}.jpg'\n",
        "    generate_images(val_dataset, generator, path);\n",
        "    \n",
        "    manager.save()\n",
        "    checkpoints.step.assign_add(1)\n",
        "\n",
        "\n",
        "    clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayc7S9hWIIOl"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ainz9burlNU9",
        "outputId": "fe5a2035-1df9-44ad-a3df-c038420f1568"
      },
      "source": [
        "fit(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[==========                ]1273 of 3125 - Elapsed Time: 0:03:13-ETA:   0:04:24"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSQl0wPRTJEW",
        "outputId": "8d9485d8-f9f1-457b-ec10-dbd2300e4259"
      },
      "source": [
        "print(manager.checkpoints[-8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/VCS Project/checkpoints/ckpt-117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVMEkgZZhaaJ",
        "outputId": "7cf90311-be66-4f13-ddec-b1bbdbc8d8aa"
      },
      "source": [
        "checkpoints.restore(manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f85be03fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2H1NGSLTVFY",
        "outputId": "f220aa46-8fe5-41c2-b118-aca2b9bf3132"
      },
      "source": [
        "print(int(checkpoints.step))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7JcGLMjUA79",
        "outputId": "ca0e19b2-4e96-45c4-ecde-81f11f0a288e"
      },
      "source": [
        "path = f'/content/drive/My Drive/VCS Project/sample.jpg'\n",
        "generate_images(val_dataset, generator, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH1d3qBbg_l3"
      },
      "source": [
        "generator.save('/content/drive/My Drive/VCS Project/Best model/', include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6R44E9MoUxh"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "yNkdUVvchdQp",
        "outputId": "51d0f5ae-8599-4bc0-8ff5-edf642100cc4"
      },
      "source": [
        "generator = tf.keras.models.load_model('/content/drive/My Drive/VCS Project/Best model/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ddfe3305640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/VCS Project/Best model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJnI8dtVTYWg"
      },
      "source": [
        "shutil.copy(\"/content/drive/My Drive/VCS Project/Test.zip\", \".\")\n",
        "!unzip -q Test.zip\n",
        "!rm Test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wk7SjqZxlbG5",
        "outputId": "2f7033c1-a6e1-4275-e75b-3bc2d8188a76"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "test_paths = tf.data.Dataset.list_files('/content/Test/*.jpg', shuffle=False)\n",
        "test_dataset = test_paths.map(load_image_test, deterministic=True)\\\n",
        "                          .batch(BATCH_SIZE)\\\n",
        "                          .prefetch(AUTOTUNE)\n",
        "\n",
        "for Ls, _, file_paths in test_dataset:\n",
        "\n",
        "  fake_ABs = generator.predict(Ls)\n",
        "\n",
        "  fake_LABs = tf.concat([Ls, fake_ABs], axis=-1)\n",
        "  fake_LABs = denormalise(fake_LABs)\n",
        "  fake_RGBs = convert2rgb(fake_LABs)\n",
        "\n",
        "  for (fake, file_path) in zip(fake_RGBs, file_paths):\n",
        "    fake_img = tf.image.convert_image_dtype(fake, dtype=tf.uint8)\n",
        "    img = tf.image.encode_jpeg(fake_img)\n",
        "\n",
        "    filename = os.path.basename(file_path.numpy())\n",
        "    save_path= f'/content/examples/{filename.decode(\"utf-8\")}'\n",
        "    tf.io.write_file(save_path, img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5831dade4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mfake_ABs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mfake_LABs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_ABs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JiwWCeNTOpQ"
      },
      "source": [
        "!rm -R /content/examples_resnet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS6ZvVAGfGKL"
      },
      "source": [
        "!zip -r examples_resnet.zip /content/examples/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vaR1tW7GZZd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}